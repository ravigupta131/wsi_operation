{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "from tiatoolbox.wsicore import wsireader\n",
    "\n",
    "from sub_functions import initialize_df\n",
    "from sub_functions import create_mask\n",
    "from sub_functions import create_random_patches\n",
    "from sub_functions import colornorm_patch\n",
    "from sub_functions import filter_by_nuclie_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad90a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='preprocess (mask, patch, filter, colornorm) data')\n",
    "\n",
    "parser.add_argument('--source_csv', type = str, default = 'test.csv',help='path to csv file containing image data')\n",
    "parser.add_argument('--save_dir', type = str, default= 'results_folder',help='directory to save processed data')\n",
    "parser.add_argument('--patch_size', type = int, default=256,help='patch_size')\n",
    "parser.add_argument('--mask_scale', type=int, default=4, help='scale factor for masking i.e mask size is scale*patch_size')\n",
    "parser.add_argument('--patch_scale', type=int, default=2, help='patch size for random patching is scale*patch_size')\n",
    "parser.add_argument('--colornorm_scale', type=int, default=2, help='patch size for colornorm is scale*patch_size')\n",
    "parser.add_argument('--nuclie_scale', type=int, default=2, help='patch size for nuclie filtering is scale*patch_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # creating directories to save results\n",
    "    mask_save_dir = os.path.join(args.save_dir, 'masks')\n",
    "    patch_save_dir = os.path.join(args.save_dir, 'sample_patches')\n",
    "    nucliecount_save_dir = os.path.join(args.save_dir, 'nuclie_filtering')\n",
    "    colornorm_save_dir = os.path.join(args.save_dir, 'patches')\n",
    "\n",
    "    directories = {'save_dir': args.save_dir,\n",
    "                'mask_save_dir' : mask_save_dir,\n",
    "                'patch_save_dir': patch_save_dir,\n",
    "                'nucliecount_save_dir':nucliecount_save_dir,\n",
    "                'colornorm_save_dir':colornorm_save_dir}\n",
    "\n",
    "    print('source_csv: ', args.source_csv)\n",
    "    for key, val in directories.items():\n",
    "        print(key,':', val)\n",
    "        os.makedirs(val, exist_ok=True)\n",
    "\n",
    "    # Taking csv input\n",
    "    slides_info = pd.read_csv(args.source_csv)\n",
    "    df = initialize_df(slides_info)\n",
    "    mask = df['process'] == 1\n",
    "    process_stack = df[mask]\n",
    "    total = len(process_stack)\n",
    "\n",
    "    for i in range(total):\n",
    "        # try:\n",
    "        # taking input\n",
    "        df.to_csv(os.path.join(args.save_dir, 'processed_result.csv'), index=False)\n",
    "        idx = process_stack.index[i]\n",
    "        slide_id = process_stack.loc[idx, 'slide_id']\n",
    "        case_id = process_stack.loc[idx, 'case_id']\n",
    "        full_path = process_stack.loc[idx,'slide_path']\n",
    "\n",
    "        # slide_id = 'TCGA-05-4382-01Z-00-DX1'\n",
    "        # full_path = '/home/lung/ravi/preprocessing/TCGA-05-4382-01Z-00-DX1.76b49a4c-dbbb-48b0-b677-6d3037e5ce88.svs'\n",
    "\n",
    "        print(\"\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
    "        print('processing {}'.format(slide_id))\n",
    "\n",
    "        # making slide-level diretories\n",
    "        os.makedirs(os.path.join(patch_save_dir, slide_id), exist_ok=True)\n",
    "        os.makedirs(os.path.join(patch_save_dir, slide_id, 'colornorm_patches'), exist_ok=True)\n",
    "\n",
    "        # checking if color-norm is already done, if yes then skip the wsi\n",
    "        if os.path.isfile(os.path.join(colornorm_save_dir, slide_id + '.h5')):\n",
    "            print('{} already exist in destination location, skipped'.format(slide_id))\n",
    "            df.loc[idx, 'status'] = 'already_exist'\n",
    "            continue\n",
    "\n",
    "        # opening wsi\n",
    "        wsi_reader = wsireader.WSIReader.open(input_img= full_path)\n",
    "        wsi = openslide.open_slide(full_path)\n",
    "        wsi_dim = wsi.level_dimensions[0]\n",
    "\n",
    "        # Mask\n",
    "        time1 = time.time()\n",
    "        label_bool = create_mask(wsi, slide_id, wsi_dim, args.patch_size, args.mask_scale, mask_save_dir, patch_save_dir)\n",
    "        time2 = time.time()\n",
    "        df.loc[idx, 'mask_status'] = 'done'\n",
    "        df.loc[idx, 'mask_time'] = time2 - time1\n",
    "\n",
    "        print('mask done ----------')\n",
    "\n",
    "        # Patch\n",
    "        patches, num_patches_after_mask = create_random_patches(wsi, slide_id, args.patch_size, args.patch_scale, args.mask_scale, patch_save_dir, label_bool)\n",
    "        time3 = time.time()\n",
    "        df.loc[idx, 'patch_status'] = 'done'\n",
    "        df.loc[idx, 'num_patches_after_mask'] = num_patches_after_mask\n",
    "        df.loc[idx, 'num_patches_after_patching'] = len(patches)\n",
    "        df.loc[idx, 'patch_time'] = time3 - time2\n",
    "\n",
    "        print('patch done ----------')\n",
    "\n",
    "        # nuclie count\n",
    "        filtered_patches = filter_by_nuclie_count(wsi_reader, case_id, slide_id, args.patch_size, args.nuclie_scale, nucliecount_save_dir, patches)\n",
    "        time4 = time.time()\n",
    "        df.loc[idx, 'nucliecount_status'] = 'done'\n",
    "        df.loc[idx, 'num_patches_after_filtering'] = len(filtered_patches)\n",
    "        df.loc[idx, 'nucliecount_time'] = time4 - time3\n",
    "\n",
    "        print('nuclie filtering done ----------')\n",
    "\n",
    "        # color normalisation\n",
    "        colornorm_patch(wsi_reader, slide_id, args.patch_size, args.colornorm_scale, colornorm_save_dir, patch_save_dir, filtered_patches, wsi_dim)\n",
    "        time5 = time.time()\n",
    "        df.loc[idx, 'colornorm_status'] = 'done'\n",
    "        df.loc[idx, 'colornorm_time'] = time5 - time4\n",
    "\n",
    "        print('color normalization done ----------')\n",
    "\n",
    "        df.loc[idx, 'process'] = 0\n",
    "        df.loc[idx, 'total_time_taken'] = time5 - time1\n",
    "        df.to_csv(os.path.join(args.save_dir, 'processed_result.csv'), index=False)\n",
    "\n",
    "        # except:\n",
    "        # continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab24c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
