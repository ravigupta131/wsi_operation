{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions for data-preprocessing\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# histomicsTK for masking and color normalization\n",
    "from histomicstk.saliency.tissue_detection import get_slide_thumbnail, get_tissue_mask\n",
    "from histomicstk.preprocessing.color_normalization.deconvolution_based_normalization import deconvolution_based_normalization\n",
    "\n",
    "# histocartography for nuclie filtering\n",
    "from histocartography.preprocessing import NucleiExtractor, DeepFeatureExtractor, KNNGraphBuilder\n",
    "from tiatoolbox.wsicore import wsireader\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_df(slides):\n",
    "\n",
    "    total = len(slides)\n",
    "\n",
    "    # columns to copy from old csv to new\n",
    "    slide_path = slides.slide_path.values\n",
    "    slide_id = slides.slide_id.values\n",
    "    case_id = slides.case_id.values\n",
    "    dataset = slides.dataset.values\n",
    "    objective_power = slides.objective_power.values\n",
    "    slide_dimensions = slides.slide_dimensions.values\n",
    "    level_count = slides.level_count.values\n",
    "    level_dimensions = slides.level_dimensions.values\n",
    "    vendor = slides.vendor.values\n",
    "    label = slides.label.values\n",
    "\n",
    "    default_df_dict = {'slide_path': slide_path,\n",
    "                        'case_id': case_id,\n",
    "                        'slide_id': slide_id,\n",
    "                        'label': label,\n",
    "                        'dataset': dataset,\n",
    "                        'objective_power': objective_power,\n",
    "                        'slide_dimensions': slide_dimensions,\n",
    "                        'level_count': level_count,\n",
    "                        'level_dimensions': level_dimensions,\n",
    "                        'level_downsamples': level_dimensions,\n",
    "                        'vendor':vendor}\n",
    "    # adding following columns to input csv\n",
    "    default_df_dict.update({\n",
    "        'process': np.full((total), 1, dtype=np.uint8),\n",
    "        'mask_status': np.full((total), 'tbp'),\n",
    "        'patch_status': np.full((total), 'tbp'),\n",
    "        'colornorm_status': np.full((total), 'tbp'),\n",
    "        'nucliecount_status': np.full((total), 'tbp'),\n",
    "        'num_patches_after_mask' : np.full((total), 0, dtype = np.int32),\n",
    "\t\t'num_patches_after_patching' : np.full((total), 0, dtype = np.int32),\n",
    "\t\t'num_patches_after_filtering' : np.full((total), 0, dtype = np.int32),\n",
    "\t\t'mask_time' : np.full((total), 0.0, dtype = np.float32),\n",
    "\t\t'patch_time' : np.full((total), 0.0, dtype = np.float32),\n",
    "\t\t'nucliecount_time' : np.full((total), 0.0, dtype = np.float32),\n",
    "\t\t'colornorm_time' : np.full((total), 0.0, dtype = np.float32),\n",
    "\t\t'total_time_taken' : np.full((total), 0.0, dtype = np.float32)\n",
    "\t\t})\n",
    "\n",
    "\ttemp_copy = pd.DataFrame(default_df_dict) # temporary dataframe w/ default params\n",
    "\t\n",
    "\t# find key in provided df\n",
    "\t# if exist, fill empty fields w/ default values, else, insert the default values as a new column\n",
    "\tfor key in default_df_dict.keys(): \n",
    "\t\tif key in slides.columns:\n",
    "\t\t\tmask = slides[key].isna()\n",
    "\t\t\tslides.loc[mask, key] = temp_copy.loc[mask, key]\n",
    "\t\telse:\n",
    "\t\t\tslides.insert(len(slides.columns), key, default_df_dict[key])\n",
    "\treturn slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_h5(h5_file_path, colornorm_patch, patch_coord, wsi_dim, slide_id, patch_size):\n",
    "\t# opening file in write mode\n",
    "\tfile = h5py.File(h5_file_path, \"w\")\n",
    "\tcolornorm_patch = np.array(colornorm_patch)[np.newaxis,...]\n",
    "\n",
    "\t# coordinates dataset\n",
    "\tcoord_dset = file.create_dataset('coords', shape=(1, 2), maxshape=(None, 2), chunks=(1, 2), dtype=np.int32)\n",
    "\tcoord_dset[:] = patch_coord\n",
    "\n",
    "\tcoord_dset.attrs['patch_level'] = 0\n",
    "\tcoord_dset.attrs['patch_size'] = patch_size\n",
    "\n",
    "\t# patch dataset\n",
    "\timg_dtype = colornorm_patch.dtype\n",
    "\timg_shape = colornorm_patch.shape\n",
    "\tmaxshape = (None,) + img_shape[1:]\n",
    "\tpatch_dset = file.create_dataset('imgs', shape=img_shape, maxshape=maxshape, chunks=img_shape, dtype=img_dtype)\n",
    "\tpatch_dset[:] = colornorm_patch\n",
    "\n",
    "\tpatch_dset.attrs['patch_level'] = 0\n",
    "\tpatch_dset.attrs['wsi_name'] = slide_id\n",
    "\tpatch_dset.attrs['downsample'] = 1.0\n",
    "\tpatch_dset.attrs['level_dim'] = wsi_dim\n",
    "\tpatch_dset.attrs['downsampled_level_dim'] = wsi_dim\n",
    "\n",
    "\tfile.close()\n",
    "\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patch_h5(h5_file_path, colornorm_patch, patch_coord):\n",
    "\t# opening file in append mode\n",
    "\tfile = h5py.File(h5_file_path, \"a\")\n",
    "\tcolornorm_patch = np.array(colornorm_patch)[np.newaxis,...]\n",
    "\n",
    "\t# coordinates dataset\n",
    "\tcoord_dset = file['coords']\n",
    "\tdata_shape = (1, 2)\n",
    "\tcoord_dset.resize(len(coord_dset) + data_shape[0], axis=0)\n",
    "\tcoord_dset[-data_shape[0]:] = patch_coord\n",
    "\n",
    "\t# patch dataset\n",
    "\tpatch_dset = file['imgs']\n",
    "\tdata_shape = colornorm_patch.shape\n",
    "\tpatch_dset.resize(file['imgs'].shape[0] + data_shape[0], axis=0)\n",
    "\tpatch_dset[-data_shape[0]:] = colornorm_patch\n",
    "\n",
    "\tfile.close()\n",
    "\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bccb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(wsi, slide_id, wsi_dim, patch_size, mask_scale, mask_save_dir, patch_save_dir):\n",
    "\n",
    "\tdeconvolve_first = True\n",
    "\tn_thresholding_steps = 1\n",
    "\t# mask dimentions are (scale/patch_size) times of original image. In our case, its 4/256 = 1/64\n",
    "\tmask_dim = (int(wsi_dim[0]*mask_scale/patch_size), int(wsi_dim[1]*mask_scale/patch_size))\n",
    "\n",
    "\t# getting the image thumbnail using openslides's get_thumbnail function\n",
    "\twsi_thumbnail_rgb = wsi.get_thumbnail(mask_dim)\t# returns a PIL image\n",
    "\n",
    "\t# converting Image object to numpy array\n",
    "\twsi_thumbnail_array = np.array(wsi_thumbnail_rgb)\t\n",
    "\n",
    "\t# getting tissue mask using histomicsTk library get_tissue_mask function\n",
    "\tlabeled, mask = get_tissue_mask(wsi_thumbnail_array, deconvolve_first=deconvolve_first, n_thresholding_steps=n_thresholding_steps, sigma=0., min_size=30)\n",
    "\n",
    "\t# converting labeled matrix to 0-1 matrix\n",
    "\tlabel_bool = labeled\n",
    "\tlabel_bool[labeled!=0] = 1\n",
    "\n",
    "\t# generating, normalising and converting mask to image object\n",
    "\twsi_thumbnail_array[label_bool==False] = 0*wsi_thumbnail_array[label_bool==False]\n",
    "\t# wsi_thumbnail_array = wsi_thumbnail_array/max(wsi_thumbnail_array)\n",
    "\twsi_mask_rgb = Image.fromarray(wsi_thumbnail_array)\n",
    "\n",
    "\t# saving the mask and image thumbnail\n",
    "\timg_path = os.path.join(mask_save_dir, slide_id + '__img.png')\n",
    "\tmask_path = os.path.join(mask_save_dir, slide_id + '__mask.png')\n",
    "\timg_path2 = os.path.join(patch_save_dir, slide_id, slide_id + '__img.png')\n",
    "\twsi_thumbnail_rgb.save(img_path)\n",
    "\twsi_mask_rgb.save(mask_path)\n",
    "\twsi_thumbnail_rgb.save(img_path2)\n",
    "\n",
    "\treturn label_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_patches(wsi, slide_id, patch_size, patch_scale, mask_scale, patch_save_dir, label_bool):\n",
    "\n",
    "\t# parameters\n",
    "\tpatch_size_on_mask = int(mask_scale*patch_scale)\t# (mask_scale/patch_size)*(patch_scale*patch_size)\n",
    "\tpatch_size_on_wsi = int(patch_scale*patch_size)\t\n",
    "\tarea_threshold = 0.9 \t# 90%\n",
    "\tmax_patches = 500\t\t# max number of patches to store per wsi\n",
    "\tnum_patches_png = 50\t# number of patches png images to store as samples\n",
    "\n",
    "\t# looping over the mask to filter patches according to area threshold\n",
    "\tstart_x = np.min(np.nonzero(label_bool)[0])\n",
    "\tstart_y = np.min(np.nonzero(label_bool)[1])\n",
    "\tstop_x = np.max(np.nonzero(label_bool)[0])\n",
    "\tstop_y = np.max(np.nonzero(label_bool)[1])\n",
    "\tstep_size_xy = patch_size_on_mask\n",
    "\tpatches = []\n",
    "\tfor y in range(start_y, stop_y, step_size_xy):\n",
    "\t\tfor x in range(start_x, stop_x, step_size_xy):\n",
    "\t\t\tarr = label_bool[x:x+patch_size_on_mask, y:y+patch_size_on_mask]\n",
    "\t\t\tif np.sum(arr) > area_threshold*(patch_size_on_mask^2):\n",
    "\t\t\t\t# (x,y) coordinate on numpy array corresponds to (y,x) coordinate in PIL image\n",
    "\t\t\t\twsi_patch_coord = (y*int(patch_size_on_wsi/patch_size_on_mask), x*int(patch_size_on_wsi/patch_size_on_mask))\n",
    "\t\t\t\tpatches.append(wsi_patch_coord)\n",
    "\n",
    "\t# taking random at max max_patches number of patches randomly from patches array \n",
    "\ttotal_patches = len(patches)\n",
    "\tprint('total patches - ', total_patches)\n",
    "\tindex = np.random.choice(total_patches, size=min(total_patches,max_patches), replace=False)\n",
    "\trandom_patches = []\n",
    "\tfor j in range(len(index)):\n",
    "\t\trandom_patches.append(patches[index[j]])\n",
    "\n",
    "\t# saving png image of num_patches_png number of patches for visualization\n",
    "\tfor i in range(min(len(random_patches), num_patches_png)):\n",
    "\t\tsample = wsi.read_region(random_patches[i], 0, (patch_size_on_wsi,patch_size_on_wsi))\n",
    "\t\tpng_file_name = os.path.join(patch_save_dir, slide_id, slide_id + '__' + str(random_patches[i][0]) + '_' + str(random_patches[i][1]) + '.png')\n",
    "\t\tsample.save(png_file_name)\n",
    "\n",
    "\treturn random_patches, total_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_nuclie_count(wsi_reader, case_id, slide_id, patch_size, nuclie_scale, nucliecount_save_dir, patches):\n",
    "\n",
    "\t# things to save in csv file\n",
    "\trecord = {'case_id':[], 'slide_id':[], 'patch_id':[], 'patch_coord_x': [], 'patch_coord_y': [], 'num_cells':[],'time':[],'valid_patch':[]}\n",
    "\n",
    "\t# filter limits - 2 options - absolute or percentile. choosing absolute\n",
    "\t# upper_limit = 1000\n",
    "\tlower_limit = 50\n",
    "\n",
    "\t# initialising nuclie detector\n",
    "\tnuclei_detector = NucleiExtractor()\n",
    "\tfeature_extractor = DeepFeatureExtractor(architecture='resnet34', patch_size=72)\n",
    "\n",
    "\t# filtering patches\n",
    "\tfiltered_patches = []\n",
    "\tfor i in range(len(patches)):\n",
    "\t\tprint('nuclie filtering patch - ', i+1 , '/', len(patches))\n",
    "\t\tt_start = time.time()\n",
    "\t\tsample = wsi_reader.read_region(patches[i], 0, (nuclie_scale*patch_size,nuclie_scale*patch_size))\n",
    "\t\t_, cell = nuclei_detector.process(sample)\n",
    "\t\tt_stop = time.time()\n",
    "\n",
    "\t\t# saving in dictionary\n",
    "\t\trecord['case_id'].append(case_id)\n",
    "\t\trecord['slide_id'].append(slide_id)\n",
    "\t\trecord['patch_id'].append(i)\n",
    "\t\trecord['patch_coord_x'].append(patches[i][0])\n",
    "\t\trecord['patch_coord_y'].append(patches[i][1])\n",
    "\t\trecord['num_cells'].append(len(cell))\n",
    "\t\trecord['time'].append(t_stop-t_start)\n",
    "\n",
    "\t\tif len(cell) >= lower_limit:\n",
    "\t\t\trecord['valid_patch'].append(1)\n",
    "\t\t\tfiltered_patches.append(patches[i])\n",
    "\t\telse:\n",
    "\t\t\trecord['valid_patch'].append(0)\n",
    "\n",
    "\tdf = pd.DataFrame(record)\n",
    "\tdf.to_csv(os.path.join(nucliecount_save_dir, slide_id +'__filtered.csv'),index=False)\n",
    "\n",
    "\treturn filtered_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d48745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colornorm_patch(wsi_reader, slide_id, patch_size, colornorm_scale, colornorm_save_dir, patch_save_dir, patches, wsi_dim):\n",
    "\t# using histomicTK for color norm with W_target as given in its documentation\n",
    "\t'''\n",
    "\tTCGA-A2-A3XS-DX1_xmin21421_ymin37486_.png, Amgad et al, 2019)\n",
    "\tfor macenco (obtained using rgb_separate_stains_macenko_pca() and reordered such that columns are the order: Hamtoxylin, Eosin, Null\n",
    "\t'''\n",
    "\tW_target = np.array([[0.5807549,  0.08314027,  0.08213795],[0.71681094,  0.90081588,  0.41999816],[0.38588316,  0.42616716, -0.90380025]])\n",
    "\n",
    "\th5_file_path = os.path.join(colornorm_save_dir, slide_id + '.h5')\n",
    "\tif(len(patches)>0):\n",
    "\t\t# saving 1st patch to initialise dataset\n",
    "\t\tprint('color normalization patch - ', 1 , '/', len(patches))\n",
    "\t\n",
    "\t\tsample = wsi_reader.read_region(patches[0], 0, (colornorm_scale*patch_size,colornorm_scale*patch_size))\n",
    "\t\tpng_file_name = os.path.join(patch_save_dir, slide_id, 'colornorm_patches', slide_id + '__' + str(patches[0][0]) + '_' + str(patches[0][1]) + '.png')\n",
    "\t\tsample_image = Image.fromarray(sample)\n",
    "\t\tsample_image.save(png_file_name)\n",
    "\n",
    "\t\ttissue_rgb_normalized = deconvolution_based_normalization(sample, W_target=W_target)\n",
    "\t\tpng_file_name = os.path.join(patch_save_dir, slide_id, 'colornorm_patches', slide_id + '__' + str(patches[0][0]) + '_' + str(patches[0][1]) + '_cn.png')\n",
    "\t\tcolornorm_image = Image.fromarray(tissue_rgb_normalized)\n",
    "\t\tcolornorm_image.save(png_file_name)\n",
    "\n",
    "\t\t#dividing patches in parts \n",
    "\t\tfor iy in range(colornorm_scale):\n",
    "\t\t\tfor ix in range(colornorm_scale):\n",
    "\n",
    "\t\t\t\t# bounding box coordinates of patch\n",
    "\t\t\t\tleft = patch_size*ix\n",
    "\t\t\t\tupper = patch_size*iy\n",
    "\t\t\t\tright = left + patch_size\n",
    "\t\t\t\tlower = upper + patch_size\n",
    "\n",
    "\t\t\t\t# data to save in h5 file\n",
    "\t\t\t\tsub_patch_coord = (patches[0][0] + patch_size*ix, patches[0][1] + patch_size*iy)\n",
    "\t\t\t\tsub_patch_img = colornorm_image.crop(box = (left, upper, right, lower))\n",
    "\n",
    "\t\t\t\t# save sub patches of 1 image\n",
    "\t\t\t\tpng_file_name = os.path.join(patch_save_dir, slide_id, 'colornorm_patches', slide_id + '__' + str(ix) + str(iy) + '_' + str(sub_patch_coord[0]) + '_' + str(sub_patch_coord[1]) + '_cn.png')\n",
    "\t\t\t\tsub_patch_img.save(png_file_name)\n",
    "\n",
    "\t\t\t\t# initialise h5 file for the first patch\n",
    "\t\t\t\tif iy == 0 and ix == 0:\n",
    "\t\t\t\t\tinitialise_h5(h5_file_path, sub_patch_img, sub_patch_coord, wsi_dim, slide_id, patch_size)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsave_patch_h5(h5_file_path, sub_patch_img, sub_patch_coord)\n",
    "\n",
    "\t\t# looping over patches to color normalise them\n",
    "\t\tfor i in range(1,len(patches)):\n",
    "\t\t\tprint('color normalization patch - ', i+1 , '/', len(patches))\n",
    "\n",
    "\t\t\t# take sample, color normalise and convert to image object\n",
    "\t\t\tsample = wsi_reader.read_region(patches[i], 0, (colornorm_scale*patch_size,colornorm_scale*patch_size))\n",
    "\t\t\tsample_image = Image.fromarray(sample)\n",
    "\t\t\t# png_file_name = os.path.join(colornorm_save_dir, slide_id, str(i) + '_' + slide_id + '__' + str(patches[i][0]) + '_' + str(patches[i][1]) + '.png')\n",
    "\t\t\t# sample_image.save(png_file_name)\n",
    "\n",
    "\t\t\ttissue_rgb_normalized = deconvolution_based_normalization(sample, W_target=W_target)\n",
    "\t\t\tcolornorm_image = Image.fromarray(tissue_rgb_normalized)\n",
    "\t\t\t# png_file_name = os.path.join(colornorm_save_dir, slide_id, str(i) + '_' + slide_id + '__' + str(patches[i][0]) + '_' + str(patches[i][1]) + 'cn.png')\n",
    "\t\t\t# colornorm_image.save(png_file_name)\n",
    "\n",
    "\t\t\tfor iy in range(colornorm_scale):\n",
    "\t\t\t\tfor ix in range(colornorm_scale):\n",
    "\t\t\t\t\t# bounding box coordinates of patch\n",
    "\t\t\t\t\tleft = patch_size*ix\n",
    "\t\t\t\t\tupper = patch_size*iy\n",
    "\t\t\t\t\tright = left + patch_size\n",
    "\t\t\t\t\tlower = upper + patch_size\n",
    "\t\t\t\t\t# data to save in h5 file\n",
    "\t\t\t\t\tsub_patch_coord = (patches[0][0] + patch_size*ix, patches[0][1] + patch_size*iy)\n",
    "\t\t\t\t\tsub_patch_img = colornorm_image.crop(box = (left, upper, right, lower))\n",
    "\t\t\t\t\tsave_patch_h5(h5_file_path, sub_patch_img, sub_patch_coord)\n",
    "\treturn 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd176f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853467e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
